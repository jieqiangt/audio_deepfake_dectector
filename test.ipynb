{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "src_dir = './data/all'\n",
    "train_dest_dir = './data/train'\n",
    "val_dest_dir = './data/val'\n",
    "test_dest_dir = './data/eval'\n",
    "\n",
    "if len(os.listdir(train_dest_dir)) >= 1:\n",
    "    # return flac files into original folder if there are any\n",
    "    print(f'found {len(os.listdir(train_dest_dir))\n",
    "                    } flac file(s) in train directory...')\n",
    "    print(f'transferring flac files back to train directory...')\n",
    "    for file in os.listdir(train_dest_dir):\n",
    "        shutil.move(f\"{train_dest_dir}/{file}\", f\"{src_dir}/{file}\")\n",
    "\n",
    "if len(os.listdir(val_dest_dir)) >= 1:\n",
    "    # return flac files into original folder if there are any\n",
    "    print(f'found {len(os.listdir(val_dest_dir))\n",
    "                    } flac file(s) in val directory...')\n",
    "    print(f'transferring flac files back to train directory...')\n",
    "    for file in os.listdir(val_dest_dir):\n",
    "        shutil.move(f\"{val_dest_dir}/{file}\", f\"{src_dir}/{file}\")\n",
    "\n",
    "if len(os.listdir(test_dest_dir)) >= 1:\n",
    "    # return flac files into original folder if there are any\n",
    "    print(f'found {len(os.listdir(test_dest_dir))\n",
    "                    } flac file(s) in val directory...')\n",
    "    print(f'transferring flac files back to train directory...')\n",
    "    for file in os.listdir(test_dest_dir):\n",
    "        shutil.move(f\"{test_dest_dir}/{file}\", f\"{src_dir}/{file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "df = pd.read_csv('./data/all_labels.txt', sep=' ', header=None)\n",
    "df.rename(columns={1: 'key', 5: 'label', 7: 'group'}, inplace=True)\n",
    "df = df[['key', 'label', 'group']]\n",
    "\n",
    "for file in df[df['label'] == 'bonafide']['key']:\n",
    "    shutil.move(f\"./data/all/{file}.flac\", f\"./data/all_bonafide/{file}.flac\")\n",
    "    \n",
    "for file in df[df['label'] == 'spoof']['key']:\n",
    "    shutil.move(f\"./data/all/{file}.flac\", f\"./data/all_spoof/{file}.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from models import SimpleCNN_STFT_FRAMESIZE_1024, FOURTH_CNN_STFT_FRAMESIZE_1024\n",
    "import torch\n",
    "import math\n",
    "\n",
    "from scripts import predict_single_audio\n",
    "from data_utils import split_audio, preprocess_audio_for_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# read in audio\n",
    "test_file = 'test_audio.mp3'\n",
    "data_dir = './data/'\n",
    "file_path = f'{data_dir}/{test_file}'\n",
    "SAMPLE_RATE = 16000\n",
    "# ../data/trial/DF_E_3521558.flac\n",
    "\n",
    "\n",
    "audio, _ = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "\n",
    "print(audio.shape[0])\n",
    "#initialize model\n",
    "# model = SimpleCNN_STFT_FRAMESIZE_1024()\n",
    "model = SimpleCNN_STFT_FRAMESIZE_1024()\n",
    "# model.load_state_dict(torch.load('./models/FOURTH_CNN_STFT_FRAMESIZE_1024_2SEC_1_weights.pt', weights_only=True))\n",
    "\n",
    "y_probs = predict_single_audio(audio, model)\n",
    "\n",
    "# SAMPLE_RATE = 16000\n",
    "# # split audio into ~2s chunks\n",
    "# sample_size = 32000\n",
    "# max_audio_size = audio.shape[0]\n",
    "# num_secs = math.ceil(max_audio_size/SAMPLE_RATE)\n",
    "\n",
    "# audio_splits = []\n",
    "# for start_range in range(0, max_audio_size, sample_size):\n",
    "#     audio_split = split_audio(\n",
    "#         audio, start_range, sample_size, max_audio_size)\n",
    "#     audio_splits.append(audio_split)\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# if device == \"cpu\":\n",
    "#     raise ValueError(\"GPU not detected!\")\n",
    "\n",
    "# model = model.to(device)\n",
    "\n",
    "# y_probs = []\n",
    "# for X_raw in audio_splits:\n",
    "\n",
    "#     X = preprocess_audio_for_cnn(X_raw)\n",
    "#     break\n",
    "    \n",
    "#     X = X.to(device)\n",
    "#     y = model(X)\n",
    "#     y_probs.extend(np.repeat(y.detach().cpu().numpy()[0][1], 2).tolist())\n",
    "\n",
    "# print(len(y_probs))\n",
    "# y_probs = np.array(y_probs[0:num_secs])\n",
    "# print(len(y_probs))\n",
    "    \n",
    "# if audio is 2.5 seconds -> ground truth should be an array of size 3\n",
    "# if audio is exactly 2 seconds ->ground truth should be an array of size 2\n",
    "# if audio is 1.99 seconds ->ground truth should be an array of size 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. files in  dataloader: 77\n"
     ]
    }
   ],
   "source": [
    "from data_utils import create_dataloader, Dataset_ASVspoof2021_Raw, Dataset_ASVspoof2021_STFT\n",
    "\n",
    "batch_size = 12\n",
    "train_labels_path = './data/trial_labels.txt'\n",
    "train_data_path = './data/trial'\n",
    "train_loader = create_dataloader(\n",
    "    Dataset_ASVspoof2021_STFT, train_labels_path, train_data_path, 64000, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jieqi\\Desktop\\JQ\\code_projects\\audio_deepfake_detector\\data_utils.py:61: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  X_raw, _ = librosa.load(\n",
      "c:\\Users\\jieqi\\Desktop\\JQ\\code_projects\\audio_deepfake_detector\\venv\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 3, 513, 251])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch, (X_train, y_train) in enumerate(train_loader):\n",
    "    break\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_params: 8831586\n",
      "torch.Size([12, 2])\n"
     ]
    }
   ],
   "source": [
    "from models import AASISTModel, SimpleCNN_STFT_FRAMESIZE_1024\n",
    "import torch\n",
    "\n",
    "# \"nb_samp\": 64600,\n",
    "d_args = {\"first_conv\": 128,\n",
    "          \"filts\": [70, [1, 32], [32, 32], [32, 64], [64, 64]],\n",
    "          \"gat_dims\": [64, 32],\n",
    "          \"pool_ratios\": [0.5, 0.7, 0.5, 0.5],\n",
    "          \"temperatures\": [2.0, 2.0, 100.0, 100.0]\n",
    "          }\n",
    "\n",
    "# model = AASISTModel(d_args)\n",
    "model = SimpleCNN_STFT_FRAMESIZE_1024()\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "model = model.to('cuda')\n",
    "\n",
    "print(f'total_params: {total_params}')\n",
    "X_train = X_train.to('cuda')\n",
    "# hidden, y_pred = model(X_train, Freq_aug=False)\n",
    "\n",
    "X_train = X_train.to('cuda')\n",
    "y_pred = model(X_train)\n",
    "\n",
    "# print(hidden.shape)\n",
    "print(y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['group'] == 'hidden'].groupby('label').count()\n",
    "\n",
    "34560 * 0.01\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/all_labels.txt',sep=' ', header=None)\n",
    "df.rename(columns={1: 'key', 5: 'label', 7: 'group'},inplace=True)\n",
    "df = df[['key','label','group']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import split_audio_dataset\n",
    "\n",
    "split_audio_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_labels_path = './data/train_labels.txt'\n",
    "train_labels = pd.read_csv(\n",
    "    train_labels_path, sep=' ', names=['key', 'label'])\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.feature import delta\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "FRAME_SIZE = 1024\n",
    "HOP_SIZE = int(FRAME_SIZE/4)\n",
    "\n",
    "base_dir = './data/trial'\n",
    "key = 'DF_E_2010009'\n",
    "cut = 32300\n",
    "\n",
    "def pad_random(x: np.ndarray, max_len: int = 64600):\n",
    "    x_len = x.shape[0]\n",
    "    # if duration is already long enough\n",
    "    if x_len >= max_len:\n",
    "        stt = np.random.randint(x_len - max_len)\n",
    "        return x[stt:stt + max_len]\n",
    "\n",
    "    # if too short\n",
    "    num_repeats = int(max_len / x_len) + 1\n",
    "    padded_x = np.tile(x, (num_repeats))[:max_len]\n",
    "    return padded_x\n",
    "\n",
    "\n",
    "\n",
    "X_raw, _ = librosa.load(\n",
    "    str(f\"{base_dir}/{key}.flac\"), sr=SAMPLE_RATE)\n",
    "X_pad = pad_random(X_raw, cut)\n",
    "X_stft = librosa.stft(y=X_pad, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)\n",
    "X_log_stft = librosa.power_to_db(np.abs(X_stft)**2)\n",
    "X_delta = librosa.feature.delta(X_log_stft, width=9, order=1)\n",
    "X_delta2 = librosa.feature.delta(X_log_stft, width=9, order=2)\n",
    "stacked = [arr.reshape((1, X_log_stft.shape[0], X_log_stft.shape[1]))\n",
    "           for arr in (X_log_stft, X_delta, X_delta2)]\n",
    "X = torch.FloatTensor(np.concatenate(stacked, axis=0))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "test = torch.Tensor(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_log_stft(audio):\n",
    "    \n",
    "    audio_stft = librosa.stft(y=audio, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)\n",
    "    return librosa.power_to_db(audio_stft)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 1: STFT + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, sr = librosa.load(f'{data_path}/{files[0]}',sr=SAMPLE_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2: Raw Waveform Wav2Vec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 3: Raw Waveform AAsist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 4: Raw Waveform Wav2Vec2 + AAsist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import split_audio_dataset\n",
    "\n",
    "split_audio_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# stft with librosa\n",
    "\n",
    "\n",
    "# feed processed waveform to front_end_processor\n",
    "\n",
    "inputs = front_end_processor(audio_log_stft, sampling_rate=sr, return_tensors=\"pt\")\n",
    "\n",
    "# feed frequency into\n",
    "audio_cqt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.randint(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "max_len = 5\n",
    "\n",
    "stt = 0\n",
    "x = torch.Tensor([1,2,3,4,5])\n",
    "x[stt:stt + max_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import split_audio_dataset\n",
    "\n",
    "train_labels_file = './data/train_labels.txt'\n",
    "train_dir = './data/train'\n",
    "val_labels_file = './data/val_labels.txt'\n",
    "val_dir = './data/val'\n",
    "\n",
    "\n",
    "split_audio_dataset(train_labels_file, train_dir, val_labels_file, val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['model','iteration', 'gpu', 'num_params', 'training_time', 'min_train_loss', 'min_val_loss', 'max_train_acc', 'max_val_acc', 'threshold', 'f1', 'recall', 'precision', 'eer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./results/run_summary.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "    \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device: {}\".format(device))\n",
    "if device == \"cpu\":\n",
    "    raise ValueError(\"GPU not detected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['col_1','col_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'col_1': 'asdas', 'col_2': 2}\n",
    "pd.concat([df,pd.DataFrame.from_dict(data,orient='index').T],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "my_tensor = torch.FloatTensor([[1,2],\n",
    "                               [3,4],\n",
    "                               [5,6]])\n",
    "\n",
    "\n",
    "torch.masked_select(my_tensor, torch.BoolTensor([False,True]).repeat(batch_size,1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor([1,1,1,1,1]).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_in_epoch = 0\n",
    "predicted = torch.Tensor([0,1,1,1])\n",
    "y_truth = torch.Tensor([0,0,0,1])\n",
    "correct_in_epoch += (predicted == y_truth).sum()\n",
    "print(correct_in_epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SimpleCNN_STFT_FRAMESIZE_1024\n",
    "\n",
    "model = SimpleCNN_STFT_FRAMESIZE_1024()\n",
    "\n",
    "for layer in model.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "       layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "len(os.listdir('./data/train'))/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "src_dir = './data/trial'\n",
    "destination_dir = './data/all'\n",
    "\n",
    "for file in os.listdir(src_dir):\n",
    "    shutil.move(f\"{src_dir}/{file}\", f\"{destination_dir}/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "df = pd.read_csv('./data/trial_labels.txt',sep=' ', names=['key','label'])\n",
    "\n",
    "src_dir = './data/all'\n",
    "destination_dir = './data/trial'\n",
    "\n",
    "for file in df['key']:\n",
    "    shutil.copy(f\"{src_dir}/{file}.flac\", f\"{destination_dir}/{file}.flac\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.masked_select(y_val, torch.BoolTensor([False,True]).repeat(y_val.shape[0],1).to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "x = np.array([[1,2],[3,4],[5,6]])\n",
    "mask = np.repeat([[False,True]],3,axis=0)\n",
    "x[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_truth = [0,0]\n",
    "probs = np.array([[0.4,0.6],[0.6,0.4]])\n",
    "preds = np.argmax(probs,axis=1)\n",
    "total_correct_in_epoch = sum(preds == y_truth)\n",
    "print(total_correct_in_epoch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "src_dir = './data/train'\n",
    "destination_dir = './data/trial'\n",
    "\n",
    "df = pd.read_csv('./data/trial_labels.txt',header=None,sep=' ')\n",
    "df.rename(columns={0:'key',1:'label'},inplace=True)\n",
    "\n",
    "for key in df['key']:\n",
    "    shutil.copyfile(f'{src_dir}/{key}.flac',f'{destination_dir}/{key}.flac')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_summary = pd.DataFrame(columns=['a', 'b', 'c', 'd'])\n",
    "summary_stats = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\n",
    "\n",
    "\n",
    "final_summary = pd.concat([base_summary, pd.DataFrame.from_dict(\n",
    "    summary_stats, orient='index').T], ignore_index=True)\n",
    "final_summary = final_summary.fillna(0)\n",
    "final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def pad_random(x: np.ndarray, max_len: int = 64600):\n",
    "    x_len = x.shape[0]\n",
    "    # if duration is already long enough\n",
    "    if x_len > max_len:\n",
    "        stt = np.random.randint(x_len - max_len)\n",
    "        return x[stt:stt + max_len]\n",
    "    elif x_len == max_len:\n",
    "        return x\n",
    "\n",
    "    # if too short\n",
    "    num_repeats = int(max_len / x_len) + 1\n",
    "    padded_x = np.tile(x, (num_repeats))[:max_len]\n",
    "    return padded_x\n",
    "\n",
    "\n",
    "def calculate_audio_mean_std(data_dir, sample_size):\n",
    "    audio_file_list = os.listdir(data_dir)\n",
    "    start = random.randint(0, len(audio_file_list) - 1 - sample_size)\n",
    "\n",
    "    raw_data = []\n",
    "    delta_data = []\n",
    "    delta2_data = []\n",
    "\n",
    "    for file in audio_file_list[start:start+sample_size]:\n",
    "        SAMPLE_RATE = 16000\n",
    "        FRAME_SIZE = 1024\n",
    "        HOP_SIZE = int(FRAME_SIZE/4)\n",
    "        \n",
    "        X_raw = librosa.load(f\"{data_dir}/{file}\", sr=SAMPLE_RATE)[0]\n",
    "        X_pad = pad_random(X_raw, 32000)\n",
    "        X_stft = librosa.stft(y=X_pad, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)\n",
    "        X_log_stft = librosa.power_to_db(np.abs(X_stft)**2)\n",
    "        raw_data.extend(X_log_stft.flatten().tolist())\n",
    "        X_delta = librosa.feature.delta(X_log_stft, width=9, order=1)\n",
    "        delta_data.extend(X_delta.flatten().tolist())\n",
    "        X_delta2 = librosa.feature.delta(X_log_stft, width=9, order=2)\n",
    "        delta2_data.extend(X_delta2.flatten().tolist())\n",
    "\n",
    "        # stacked = [arr.reshape((1, X_log_stft.shape[0], X_log_stft.shape[1]))\n",
    "        #            for arr in (X_log_stft, X_delta, X_delta2)]\n",
    "        # X = torch.FloatTensor(np.concatenate(stacked, axis=0))\n",
    "    raw_mean = np.array(raw_data).mean()\n",
    "    raw_std = np.array(raw_data).std()\n",
    "    delta_mean = np.array(delta_data).mean()\n",
    "    delta_std = np.array(delta_data).std()\n",
    "    delta2_mean = np.array(delta2_data).mean()\n",
    "    delta2_std = np.array(delta2_data).std()\n",
    "\n",
    "    return [(raw_mean, raw_std), (delta_mean, delta_std), (delta2_mean, delta2_std)]\n",
    "\n",
    "\n",
    "sample_size = 2000\n",
    "data_dir = './data/train'\n",
    "\n",
    "raw_stats, delta_stats, delta2_stats = calculate_audio_mean_std(\n",
    "    data_dir, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_stats, delta_stats, delta2_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
